{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc2ec1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from torchvision import transforms, models\n",
    "from PIL import Image\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d4048e",
   "metadata": {},
   "source": [
    "Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6cc13d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "TABULAR_COLS = [\"bedrooms\",\"bathrooms\",\"sqft_living\",\"floors\",\"grade\"]\n",
    "TARGET_COL = \"log_price\"\n",
    "\n",
    "class HousePriceDataset(Dataset):\n",
    "    def __init__(self, df, img_dir, transform=None):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img_path = f\"{self.img_dir}/{row['id']}.jpg\"\n",
    "        if not os.path.exists(img_path):\n",
    "            return None\n",
    "\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        tabular = torch.tensor(row[TABULAR_COLS].values, dtype=torch.float32)\n",
    "        price = torch.tensor(row[TARGET_COL], dtype=torch.float32)\n",
    "\n",
    "        return image, tabular, price\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e56b30",
   "metadata": {},
   "source": [
    "Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c3548bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultimodalPriceModel(nn.Module):\n",
    "    def __init__(self, num_tabular):\n",
    "        super().__init__()\n",
    "        self.cnn = models.resnet18(pretrained=True)\n",
    "        self.cnn.fc = nn.Identity()\n",
    "\n",
    "        self.tabular_fc = nn.Sequential(\n",
    "            nn.Linear(num_tabular, 32),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.regressor = nn.Sequential(\n",
    "            nn.Linear(512 + 32, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, img, tab):\n",
    "        img_feat = self.cnn(img)\n",
    "        tab_feat = self.tabular_fc(tab)\n",
    "        return self.regressor(torch.cat([img_feat, tab_feat], 1)).squeeze()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a095411d",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e24d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/clean_train.csv\")\n",
    "image_transform = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n",
    "])\n",
    "\n",
    "dataset = HousePriceDataset(df, \"data/images/train\", image_transform)\n",
    "dataset_small = Subset(dataset, range(14000))\n",
    "\n",
    "loader = DataLoader(dataset_small, batch_size=4, shuffle=True)\n",
    "\n",
    "model = MultimodalPriceModel(len(TABULAR_COLS))\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "for epoch in range(2):\n",
    "    total = 0\n",
    "    for img, tab, y in loader:\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(img, tab)\n",
    "        loss = criterion(pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total += loss.item()\n",
    "    print(f\"Epoch {epoch+1}, Loss {total/len(loader):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878a0305",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "df_train=pd.read_csv('/Users/prashantmaurya/Desktop/Satellite_Property_Valuation/train_actual_vs_predicted.csv')\n",
    "\n",
    "y_true = df_train[\"actual_price\"].values\n",
    "y_pred = df_train[\"predicted_price\"].values\n",
    "\n",
    "r2 = r2_score(y_true, y_pred)\n",
    "print(\"R2 score:\", r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af11f753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Metrics (Train Dataset)\n",
      "----------------------------------\n",
      "RMSE : 139,578.85\n",
      "R² Score : 0.7549\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "df_eval = pd.read_csv(\"/Users/prashantmaurya/Desktop/Satellite_Property_Valuation/train_actual_vs_predicted.csv\")\n",
    "\n",
    "y_true = df_eval[\"actual_price\"].values\n",
    "y_pred = df_eval[\"predicted_price\"].values\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "r2 = r2_score(y_true, y_pred)\n",
    "\n",
    "print(\"Evaluation Metrics (Train Dataset)\")\n",
    "print(\"----------------------------------\")\n",
    "print(f\"RMSE : {rmse:,.2f}\")\n",
    "print(f\"R² Score : {r2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a4a96c36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python\n",
      "  Downloading opencv_python-4.12.0.88-cp37-abi3-macosx_13_0_arm64.whl.metadata (19 kB)\n",
      "Collecting numpy<2.3.0,>=2 (from opencv-python)\n",
      "  Downloading numpy-2.2.6-cp312-cp312-macosx_14_0_arm64.whl.metadata (62 kB)\n",
      "Downloading opencv_python-4.12.0.88-cp37-abi3-macosx_13_0_arm64.whl (37.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.9/37.9 MB\u001b[0m \u001b[31m39.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading numpy-2.2.6-cp312-cp312-macosx_14_0_arm64.whl (5.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m42.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: numpy, opencv-python\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.26.4\n",
      "    Uninstalling numpy-1.26.4:\n",
      "      Successfully uninstalled numpy-1.26.4\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "gensim 4.3.3 requires numpy<2.0,>=1.18.5, but you have numpy 2.2.6 which is incompatible.\n",
      "contourpy 1.2.0 requires numpy<2.0,>=1.20, but you have numpy 2.2.6 which is incompatible.\n",
      "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.2.6 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed numpy-2.2.6 opencv-python-4.12.0.88\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca5f2e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6f05e53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GradCAM:\n",
    "    def __init__(self, model, target_layer):\n",
    "        self.model = model\n",
    "        self.target_layer = target_layer\n",
    "        self.gradients = None\n",
    "        self.activations = None\n",
    "        \n",
    "        target_layer.register_forward_hook(self.save_activation)\n",
    "        target_layer.register_backward_hook(self.save_gradient)\n",
    "\n",
    "    def save_activation(self, module, input, output):\n",
    "        self.activations = output\n",
    "\n",
    "    def save_gradient(self, module, grad_input, grad_output):\n",
    "        self.gradients = grad_output[0]\n",
    "\n",
    "    def generate(self, image, tabular):\n",
    "        self.model.zero_grad()\n",
    "        output = self.model(image, tabular)\n",
    "        output.backward()\n",
    "\n",
    "        grads = self.gradients.mean(dim=[2, 3], keepdim=True)\n",
    "        cam = (grads * self.activations).sum(dim=1)\n",
    "        cam = torch.relu(cam)\n",
    "\n",
    "        cam = cam.squeeze().detach().cpu().numpy()\n",
    "        cam = cv2.resize(cam, (224, 224))\n",
    "        cam = (cam - cam.min()) / (cam.max() - cam.min() + 1e-8)\n",
    "\n",
    "        return cam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62eb7e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick one sample\n",
    "idx = 10\n",
    "img, tab, _ = dataset[idx]\n",
    "\n",
    "img = img.unsqueeze(0).to(device)\n",
    "tab = tab.unsqueeze(0).to(device)\n",
    "\n",
    "# ResNet last conv layer\n",
    "target_layer = model.cnn.layer4[-1].conv2\n",
    "\n",
    "gradcam = GradCAM(model, target_layer)\n",
    "heatmap = gradcam.generate(img, tab)\n",
    "\n",
    "# Convert image tensor to numpy\n",
    "img_np = img.squeeze().permute(1, 2, 0).cpu().numpy()\n",
    "img_np = (img_np - img_np.min()) / (img_np.max() - img_np.min())\n",
    "\n",
    "# Overlay\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.imshow(img_np)\n",
    "plt.imshow(heatmap, cmap='jet', alpha=0.5)\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Grad-CAM: Model Attention on Satellite Image\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
